import os
import numpy as np
import argparse
import csv
from sklearn import metrics
from sklearn.naive_bayes import BernoulliNB
from sklearn.svm import SVC
from sklearn.linear_model import Perceptron
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
from sklearn.externals import joblib


# this method should read the dataset and present a dictionary : (k,v) = (family,[malware_x, malware_y,...,malware_n])
# We also filter the malware family that has 20+ instances in the dataset
def read_dataset(dataset_dir = "../drebin", family_size = 20):
    malware_family = {}
    with open(dataset_dir+'/sha256_family.csv') as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        line_count = 0
        for row in csv_reader:
            if line_count == 0:
                print("reading dataset...")
                line_count += 1
            else:
                if row[1] in malware_family.keys():
                    malware_family[row[1]]+=[os.path.abspath(dataset_dir+"/feature_vectors/"+row[0])]
                else :
                    malware_family[row[1]] = [os.path.abspath(dataset_dir+"/feature_vectors/"+row[0])]
                line_count += 1
        # filter families that has too few instances in D
        aux = {}
        print ("number of families before pruning ",len(malware_family.keys()))
        for key in malware_family.keys():
            if len(malware_family[key]) >= family_size :
                aux[key] = malware_family[key]
        print ("number of families after pruning ",len(aux.keys()))
        return aux





def create_feature_vector(malware_family):
    family = 0
    malwares = []
    y = []
    for key in malware_family.keys():
        for malware in malware_family[key]:
            malwares+=[malware]
            y += [family]
        family += 1
    vectorizer = TfidfVectorizer(input="filename", tokenizer=lambda x: x.split('\n'), token_pattern=None, binary=True)
    X = vectorizer.fit_transform( malwares )
    return X,np.asarray(y)



# this method is just a wrapper for a classifier that fit the data in input and perform the test
# then it computes some evaluation metrics about the classifier
# @params: the classifier instance , the training and test datasets
# @return: the trained classifier and the accuracy w.r.t. the test set
def classifier_fit_predict_score( label, classifier , X_train, X_test, y_train, y_test):
    classifier.fit(X_train , y_train)
    y_predict = classifier.predict(X_test)
    accuracy = accuracy_score(y_test , y_predict)
    with open("./detection/"+label+"_output.txt", "a+") as text_file:
        print ("accuracy :", accuracy)
    return classifier,accuracy



def main(Args):
    families = read_dataset()
    X, y = create_feature_vector(families)

    classifiers_list = {}
    if not os.path.exists("./classification"):
        os.makedirs("./classification")
    classifiers_list["bernoulli"] = []
    classifiers_list["svm"] = []
    classifiers_list["perceptron"] = []

    skf = StratifiedKFold(n_splits=Args.cv,  shuffle=True , random_state=5 )

    for train_index, test_index in skf.split(X, y):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        bernoulli_clf = BernoulliNB()
        clf , accuracy = classifier_fit_predict_score( "Bernoulli", bernoulli_clf, X_train, X_test, y_train, y_test)
        classifiers_list["bernoulli"] += [(clf,accuracy)]

        svm_clf = SVC(kernel=Args.SVMkernel)
        clf , accuracy = classifier_fit_predict_score( "SVM", svm_clf, X_train, X_test, y_train, y_test)
        classifiers_list["svm"] += [(clf,accuracy)]

        perceptron_clf = Perceptron(eta0 = 0.1, max_iter=100, tol=1e-3)
        clf , accuracy = classifier_fit_predict_score( "Perceptron", perceptron_clf, X_train, X_test, y_train, y_test)
        classifiers_list["perceptron"] += [(clf,accuracy)]

    print( "classification for malware family complete see output scores in the txt files in ./classification" )
    print (f'we select the best estimator among the {Args.cv} for each of the classifiers and save it in a file as classifier.joblib'  )
    for clf_name in classifiers_list.keys():
        best_estimator , best_accuracy = classifiers_list[clf_name][0]
        for estimator,accuracy in classifiers_list[clf_name]:
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_estimator = estimator
        joblib.dump(best_estimator, "./classification/"+clf_name+'.joblib')
        print (f'Best estimator for {clf_name} has accuracy of {best_accuracy}')





def ParseArgs():
    Args = argparse.ArgumentParser(description="description: this script will train 3 classifiers namely naive-Bernoulli, svm , and perceptron for the task of malware classification" )
    Args.add_argument("--SVMkernel", default= "linear",help="the kernel for the svm classifier")
    Args.add_argument("--cv", type=int,default=3,help="number of set to split the dataset, default 3")
    Args.add_argument("--dataset",default="../drebin",help="the path to the dataset directory")
    return Args.parse_args()





if __name__ == "__main__":
    main(ParseArgs())

#
